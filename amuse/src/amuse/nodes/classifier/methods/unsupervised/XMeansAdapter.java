package amuse.nodes.classifier.methods.unsupervised;


import amuse.data.io.ArffDataSet;
import amuse.data.io.DataSet;
import amuse.data.io.DataSetInput;
import amuse.data.io.attributes.Attribute;
import amuse.data.io.attributes.NumericAttribute;
import amuse.interfaces.nodes.NodeException;
import amuse.interfaces.nodes.methods.AmuseTask;
import amuse.nodes.classifier.ClassificationConfiguration;
import amuse.nodes.classifier.ClassifierNodeScheduler;
import amuse.nodes.classifier.interfaces.ClassifierUnsupervisedInterface;
import amuse.preferences.AmusePreferences;
import amuse.preferences.KeysStringValue;
import amuse.util.AmuseLogger;
import amuse.util.FileOperations;
import amuse.util.LibraryInitializer;
import com.rapidminer.Process;
import com.rapidminer.example.ExampleSet;
import com.rapidminer.example.set.AbstractExampleSet;
import com.rapidminer.operator.IOContainer;
import com.rapidminer.operator.IOObject;
import com.rapidminer.operator.Operator;
import com.rapidminer.operator.clustering.clusterer.XMeans;
import com.rapidminer.operator.io.RepositoryStorer;
import com.rapidminer.operator.io.ResultWriter;
import com.rapidminer.operator.ports.InputPort;
import com.rapidminer.operator.ports.OutputPort;
import com.rapidminer.tools.OperatorService;
import com.rapidminer.tools.math.similarity.DistanceMeasures;

import java.io.File;
import java.util.ArrayList;
import java.util.List;
import java.util.StringTokenizer;

import org.apache.log4j.Level;

/**
 * Clusters given data by using the x-means clustering method via RapidMiner
 * @author Pauline Speckmann
 */
public class XMeansAdapter extends AmuseTask implements ClassifierUnsupervisedInterface {

    /** Lower and upper bound for the amount of clusters to be generated by x-means */
    private int k_min;
    private int k_max;
    
    /** Upper bounds for the max number of runs and max number of optimization steps */
    private int max_runs;
    private int max_opt_steps;
    
    /** Determines the numerical distance measure to be used */
	private String measureType;
    
    /** Should good start values be determined? */
    private boolean determine_good_start_values;
    

    @Override
    public void setParameters(String parameterString) throws NodeException {

        // Should the default parameters be used? Or are values given?
        if(parameterString == "" || parameterString == null) {
            k_min = 3;
            k_max = 60;
            max_runs = 30;
            max_opt_steps = 100;
            measureType = "EuclideanDistance";
            determine_good_start_values = true;
        } else {
            StringTokenizer tok = new StringTokenizer(parameterString, "_");
            k_min = new Integer(tok.nextToken());
            k_max = new Integer(tok.nextToken());
            max_runs = new Integer(tok.nextToken());
            max_opt_steps = new Integer(tok.nextToken());
            measureType = tok.nextToken();
            determine_good_start_values = Boolean.parseBoolean(tok.nextToken());
        }
        
        //Check if all parameters are in range
        if (k_min < 2 || k_max < 3 || max_runs < 1 || max_opt_steps < 1) {
        	throw new NodeException("XMeansAdapter: One of the parameters was out of range!");
        }
    }

    /*
     * (non-Javadoc)
     * @see amuse.interfaces.AmuseTaskInterface#initialize()
     */
    @Override
    public void initialize() throws NodeException {
        try {
            LibraryInitializer.initializeRapidMiner();
        } catch (Exception e) {
            throw new NodeException("Could not initialize RapidMiner: " + e.getMessage());
        }
    }

    /*
     * (non-Javadoc)
     * @see amuse.nodes.classifier.interfaces.ClassifierInterface#classify(java.lang.String, java.util.ArrayList, java.lang.String)
     */
    /* (non-Javadoc)
     * @see amuse.nodes.classifier.interfaces.ClassifierInterface#classify(java.lang.String)
     */
    @Override
    public void classify() throws NodeException {
        /* Gets the DataSet given by the user in the Classifier AMUSE task */
        DataSet dataSetToClassify = ((DataSetInput)((ClassificationConfiguration)this.correspondingScheduler.
         getConfiguration()).getInputToClassify()).getDataSet();

        try {
            /* Create the RapidMiner process */
            Process process = new Process();

                // Create the XMeans Operator in RM
                Operator clusterer = OperatorService.createOperator(XMeans.class);

                // Set the parameters and add the clustering to the process
                clusterer.setParameter("k_min", new Integer(k_min).toString());
                clusterer.setParameter("k_max", new Integer(k_max).toString());
                clusterer.setParameter("determine_good_start_values", String.valueOf(determine_good_start_values));
                clusterer.setParameter("max_runs", new Integer(max_runs).toString());
                clusterer.setParameter("max_optimization_steps", new Integer(max_opt_steps).toString());
                clusterer.setParameter("clustering_algorithm", "FastKMeans");
                clusterer.setParameter("add_as_label", "false");
                
                // Set the distance measure
                clusterer.setParameter(DistanceMeasures.PARAMETER_MEASURE_TYPES, DistanceMeasures.MEASURE_TYPES[DistanceMeasures.NUMERICAL_MEASURES_TYPE]);
                clusterer.setParameter(DistanceMeasures.PARAMETER_NUMERICAL_MEASURE, measureType);
                
                process.getRootOperator().getSubprocess(0).addOperator(clusterer);

                // Connect the ports so RapidMiner knows whats up
                InputPort clustererInputPort = clusterer.getInputPorts().getPortByName("example set");
                	// Return the the "clustered set" and not the "cluster model"
                OutputPort clustererOutputPort = clusterer.getOutputPorts().getPortByName("clustered set");
                InputPort processInputPort = process.getRootOperator().getSubprocess(0).getInnerSinks().getPortByIndex(0);
                OutputPort processOutputPort = process.getRootOperator().getSubprocess(0).getInnerSources().getPortByIndex(0);
                processOutputPort.connectTo(clustererInputPort);
                clustererOutputPort.connectTo(processInputPort);
                	//AmuseLogger.write("XMeansAdapter", Level.DEBUG, "Ports were connected");

            // Run the RapidMiner-Process - XMeans needs an ExampleSet so it's being converted here
            ExampleSet exampleSet = dataSetToClassify.convertToRapidMinerExampleSet();
            IOContainer result = process.run(new IOContainer(exampleSet));
            AmuseLogger.write("XMeansAdapter", Level.DEBUG, "RapidMiner XMeans finished successfully");

         	// Get the RapidMiner Result
            exampleSet = result.get(ExampleSet.class);
         	DataSet resultDataSet = new DataSet(exampleSet);
         	
         	// Edit the result so AMUSE can work with it again
         	
         		// Copy the result DataSet but without the id attribute (that RapidMiner put there)
         		DataSet amuseDataSet = new DataSet("XMeansResultDataSet");
    			for (int j=0; j<resultDataSet.getAttributeCount(); j++) {
    				// If the attribute is NOT the id copy the attribute to the amuseDataSet
    				if (!resultDataSet.getAttribute(j).getName().equals("id") && !resultDataSet.getAttribute(j).getName().equals("cluster")) {
    					amuseDataSet.addAttribute(resultDataSet.getAttribute(j));
    				}
    			}
    			
    			// Get the cluster numbers from the resultDataSet and 
    			// count how many different clusters there are (because that's how many new attributes are needed)
    			int valueAmount = resultDataSet.getAttribute(0).getValueCount();
    			Attribute clusterResultAtt = resultDataSet.getAttribute("cluster");
    			int[] clusterResultArray = new int[valueAmount];
    			
    			int maxClusterValue = 0;
        		for (int i=0; i<valueAmount; i++) {
        			String currentRawCluster = (String) clusterResultAtt.getValueAt(i);
        				// value should be something like "cluster_1" so delete the first 8 chars
        			currentRawCluster = currentRawCluster.substring(8);
        			
        			int currClusterInt = Integer.parseInt(currentRawCluster);
        			clusterResultArray[i] = currClusterInt;
        			if (maxClusterValue < currClusterInt) {
        				maxClusterValue = currClusterInt;
        			}
        		}
        		if (maxClusterValue == 0) {
        			AmuseLogger.write("XMeansAdapter", Level.ERROR , "There is only 1 giant Cluster and everything is in it!");
        		}
        		AmuseLogger.write("XMeansAdapter", Level.DEBUG, "There are " + maxClusterValue + "+1 different clusters.");
        		
        		// Create new Cluster Attributes
        		for (int c=0; c<maxClusterValue+1; c++) {
        			ArrayList<Double> clusterXvalueList = new ArrayList<Double>();
        			for (int i=0; i < clusterResultArray.length; i++) {
        				int currClusterInt = clusterResultArray[i];
        				if (currClusterInt == c) {
        					clusterXvalueList.add(i, 1.0);
        				} else {
        					clusterXvalueList.add(i, 0.0);
        				}
        			}
        			Attribute clusterX = new NumericAttribute("cluster_" + c, clusterXvalueList);
        			amuseDataSet.addAttribute(clusterX);
        		}
        		AmuseLogger.write("XMeansAdapter", Level.DEBUG, "XMeans successfully edited the result to AMUSE standad");
    		
    		// Give the amuseDataSet to the ClassificationConfiguration so it may be put together and saved there
        	// The ClassifierNodeScheduler proceedTask(...) returns or saves an ArrayList<ClassifiedSongPartitionsDescription>
            ((ClassificationConfiguration)(this.correspondingScheduler.getConfiguration())).setInputToClassify(new DataSetInput(amuseDataSet));
            
            // Save to .arff file
            String outputPath = AmusePreferences.get(KeysStringValue.AMUSE_PATH) + File.separator + "experiments" + File.separator + "XMeans_Result.arff";
            amuseDataSet.saveToArffFile(new File(outputPath));

        } catch(Exception e) {
            throw new NodeException("Error clustering data: " + e.getMessage());
        }
    }
}